{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446041aa3e684fe898bacb1643673c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a717a3f7db434e50b3e70c46244ee73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8578a9d5f1049c88025c71420cab777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e2e01a0e914d2bae4d0c5616b6f41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f31c0dd2724b16abf699bc36467683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5995803963fd4606b723e7cc75ab6598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf76bb2f493f4c11851d47dfba49c635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac61a01f36f4ecd8d6a90ad3e17d021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 7473\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 1319\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 5103\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 1083\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 70719\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 7858\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dataset at position 0 has at least one split: ['train', 'test']\nPlease pick one to interleave with the other datasets, for example: dataset['train']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m sqlctx_dataset \u001b[38;5;241m=\u001b[39m sqlctx_raw_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(gsm8k_dataset, viggo_dataset, sqlctx_dataset)\n\u001b[0;32m---> 19\u001b[0m merged_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgsm8k_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqlctx_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviggo_dataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_dataset)\n",
      "File \u001b[0;32m/data0/xjw/anaconda3/envs/llm311/lib/python3.11/site-packages/datasets/combine.py:197\u001b[0m, in \u001b[0;36mconcatenate_datasets\u001b[0;34m(dsets, info, split, axis)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset:\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a list of Dataset objects or a list of IterableDataset objects, but element at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis an empty dataset dictionary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m             )\n\u001b[0;32m--> 197\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has at least one split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pick one to interleave with the other datasets, for example: dataset[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataset))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a list of Dataset objects or a list of IterableDataset objects, but element at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset at position 0 has at least one split: ['train', 'test']\nPlease pick one to interleave with the other datasets, for example: dataset['train']"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "gsm8k_data_files = {\"train\": \"gsm8k-train.jsonl\", \"test\": \"gsm8k-test.jsonl\"}\n",
    "viggo_data_files = {\"train\": \"viggo-train.jsonl\", \"test\": \"viggo-test.jsonl\"}\n",
    "\n",
    "gsm8k_dataset = datasets.load_dataset('json', data_files=gsm8k_data_files)\n",
    "viggo_dataset = datasets.load_dataset('json', data_files=viggo_data_files)\n",
    "\n",
    "sqlctx_raw_dataset = datasets.load_dataset('json', data_files='sqlctx-train.jsonl')\n",
    "\n",
    "\n",
    "sqlctx_dataset = sqlctx_raw_dataset['train'].train_test_split(test_size=0.1)\n",
    "\n",
    "print(gsm8k_dataset, viggo_dataset, sqlctx_dataset)\n",
    "\n",
    "\n",
    "\n",
    "merged_train_dataset = datasets.concatenate_datasets([gsm8k_dataset['train'], sqlctx_dataset['train'], viggo_dataset['train']])\n",
    "merged_test_dataset = datasets.concatenate_datasets([gsm8k_dataset['test'], sqlctx_dataset['test'], viggo_dataset['test']])\n",
    "\n",
    "print(merged_train_dataset, merged_test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5cedfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 8792\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad40789",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "# raw_dataset = datasets.load_dataset(\"GEM/viggo\")\n",
    "# # train_dataset = raw_dataset[\"train\"]\n",
    "# # test_dataset = raw_dataset[\"test\"]\n",
    "for dataset_name in datasets_names_list:\n",
    "    print(\"load dataset\", dataset_name)\n",
    "    raw_dataset = datasets.load_dataset(dataset_name)\n",
    "    print(raw_dataset)\n",
    "    if \"train\" not in raw_dataset.keys() or \"test\" not in raw_dataset.keys():\n",
    "        raw_dataset = raw_dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "    train_dataset = raw_dataset[\"train\"]\n",
    "    test_dataset = raw_dataset[\"test\"]\n",
    "    print(train_dataset, test_dataset)\n",
    "    # train_dataset, eval_dataset = create_datasets(tokenizer, dataset_name, args)\n",
    "    train_datasets.append(train_dataset)\n",
    "    test_datasets.append(test_dataset)\n",
    "    \n",
    "train_dataset = datasets.concatenate_datasets(train_datasets)\n",
    "test_dataset = datasets.concatenate_datasets(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db5d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'context', 'gem_id', 'meaning_representation', 'target', 'references'],\n",
      "    num_rows: 83295\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
